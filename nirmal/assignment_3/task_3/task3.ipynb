{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'autoencoder_classifier' from '/home/nirmal/course_work/DLRG/nirmal/assignment_3/task_3/autoencoder_classifier.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('../task_1')\n",
    "import autoencoder_classifier as aec\n",
    "\n",
    "# force reload module\n",
    "import importlib\n",
    "importlib.reload(aec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m ce_loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      8\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m         reconstructed, classified \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/site-packages/torch/multiprocessing/reductions.py:305\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrebuild_storage_fd\u001b[39m(\u001b[39mcls\u001b[39m, df, size):\n\u001b[0;32m--> 305\u001b[0m     fd \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdetach()\n\u001b[1;32m    306\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m         storage \u001b[39m=\u001b[39m storage_from_cache(\u001b[39mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/multiprocessing/resource_sharer.py:58\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mwith\u001b[39;00m _resource_sharer\u001b[39m.\u001b[39mget_connection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id) \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m reduction\u001b[39m.\u001b[39;49mrecv_handle(conn)\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/multiprocessing/reduction.py:189\u001b[0m, in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m'''Receive a handle over a local connection.'''\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39mwith\u001b[39;00m socket\u001b[39m.\u001b[39mfromfd(conn\u001b[39m.\u001b[39mfileno(), socket\u001b[39m.\u001b[39mAF_UNIX, socket\u001b[39m.\u001b[39mSOCK_STREAM) \u001b[39mas\u001b[39;00m s:\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mreturn\u001b[39;00m recvfds(s, \u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/DLRG_lightening/lib/python3.10/multiprocessing/reduction.py:157\u001b[0m, in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    155\u001b[0m a \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39marray(\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    156\u001b[0m bytes_size \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mitemsize \u001b[39m*\u001b[39m size\n\u001b[0;32m--> 157\u001b[0m msg, ancdata, flags, addr \u001b[39m=\u001b[39m sock\u001b[39m.\u001b[39;49mrecvmsg(\u001b[39m1\u001b[39;49m, socket\u001b[39m.\u001b[39;49mCMSG_SPACE(bytes_size))\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m msg \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ancdata:\n\u001b[1;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = aec.AutoencoderClassifier(num_classes=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed, classified = model(data)\n",
    "        mse_loss = mse_loss_fn(reconstructed, data)\n",
    "        ce_loss = ce_loss_fn(classified, target)\n",
    "        loss = mse_loss + ce_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging and evaluation code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('DLRG_lightening')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0575a0355607170e809533c7a265d2dde46343ad8e16b5efb9d42c4b059fa3fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
